---
title: "Why Is C Faster Than C#?"
date: 2023-11-05T15:42:51+11:00
draft: true
summary: "A deep dive into why a small piece of equivalent code in C and C# perform differently"
tags:
- c
- csharp
- performance
---

# to do
- inline todo. fix the C# assembly section
- proof read

# Contents
{{< toc >}}

# This blog post in a paragraph
Why is [this C code](https://github.com/niklas-heer/speed-comparison/blob/master/src/leibniz.c)
5x faster than [this equivalent C# code](https://github.com/niklas-heer/speed-comparison/blob/master/src/cs/Program.cs)?
On my machine, the C program completes in 32ms versus 150ms for the C# program.
30ms of the difference is due to C# start-up/shutdown overhead. The other 90ms is
due to `gcc` vectorizing the loop, after being allowed to ignore some IEEE
compliance rules. This is a very specific case of numerically-intensive code:
it's not guaranteed that C will always be 5x faster than C#!

# The long story
After [making C# go fast]({{< ref "20230330_making_csharp_go_fast" >}}),
I wondered if I could do much better using a non-managed language like C.
Rewriting my game in C is a large project, so I went hunting for smaller
examples. Before long, I came across [speed comparison](https://niklas-heer.github.io/speed-comparison/),
which compares many languages performing the same small calculation of pi. It's
a trivially small piece of code which only compares a tiny portion of what each
language is capable of, but it's a good starting point for a learning exercise.

C comes in at 3 times faster than C# in the above comparison. In this blog post,
I'll investigate why, as someone with a rather patchy understanding of low level
code and performance (me).

The questions of which language is the fastest, and whether managed languages
like C# are slow have been around forever, and many people smarter than me have
written about it online. See [appendix B]({{< ref "#readings" >}}) for some
interesting reads. The generic reasons given are VM/runtime overhead, garbage
collection (GC), just-in-time compilation (JIT), array bounds checking and more.
I wasn't satisfied with generic reasons, and wanted to know specifically why two
pieces of comparable code differed.


# Running the speed comparison, poking around
[Speed comparison](https://github.com/niklas-heer/speed-comparison) is relatively
straightforward to run on a Linux-like environment. On my machine, C performed
even better than reported, averaging 35ms per run, versus 155ms for C#.

The code:
- reads a number `rounds` from a file
- iteratively calculates the value of pi, looping as many times as `rounds`
  specifies
- prints the value of pi

I tinkered with the code a bit to get an understanding of where the time was
being spent. Eliminating file I/O by hard coding `rounds` saved a few
milliseconds in both C and C#. Setting `rounds` to 1 reduced C's run time to
effectively zero, while C# still took 30ms. I assume this time is
start-up/shutdown time of the C# runtime (CLR), which I don't particularly care
about.

Out of curiosity, I quickly checked out ahead-of-time compilation
[(AOT)](https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/?tabs=net7%2Cwindows)
for C#. It only had a small impact on overall runtime, and start-up time was
still around 20ms. I didn't investigate any further.

So: ignoring file I/O and start-up time, C completes the pi calculation in 30ms,
while C# takes 120ms. The code for the calculation is almost identical:

C:
```c
for (unsigned i=2u; i < rounds; ++i) {
    double x = -1.0 + 2.0 * (i & 0x1);
    pi += (x / (2u * i - 1u));
}
```

C#:
```cs
for (int i = 2; i < rounds + 2; i++) {
    x *= -1;
    pi += (x / (2 * i - 1));
}
```

Changing the signed-ness of variables and the time at which to increment `i`
made no difference. The line `double x = -1.0 + 2.0 * (i & 0x1);` produces the
same value as `x` as `x *= -1`, but is important for reasons I'll talk about
later. First, let's take a look at the machine code that is generated by C and
C#.


# Digging into the machine code

## C
To see C disassembly, I used a tool called [objdump](https://en.wikipedia.org/wiki/Objdump).
I bypassed Earthly and ran `gcc` and `objdump` directly.
The [C compilation command in the Earthfile](https://github.com/niklas-heer/speed-comparison/blob/fbe72677a25df85e1bcc6386c6069dd163f04962/Earthfile#L116)
is:

```sh
gcc leibniz.c -o leibniz -O3 -s -static -flto -march=native \
    -mtune=native -fomit-frame-pointer -fno-signed-zeros \
    -fno-trapping-math -fassociative-math
```

I modified this slightly to make the objdump output easier to understand:
- removed `-s` to keep symbol information
- removed `-static`, so that external library code was excluded from the executable
- added `-g` to add debugging information

This didn't affect the speed of the program.

```sh
# compile the program
gcc leibniz.c -o leibniz -O3 -g -flto -march=native \
    -mtune=native -fomit-frame-pointer -fno-signed-zeros \
    -fno-trapping-math -fassociative-math

# extract the machine code in intel assembly format,
# along with other useful details to help understand
# which part of the code the assembly is for
objdump -drwlCS -Mintel leibniz > leibniz.asm
```

I've put all the assembly together in an [appendix]({{< ref "#assembly" >}}).

I'll cover the `gcc` options in more detail later. The `objdump` options are
described here: [objdump man page](https://www.man7.org/linux/man-pages/man1/objdump.1.html).

## C#
Accessing C# disassembly has a much more 'Windows-y' feel to it. You need to
use Visual Studio, pause the program at a breakpoint, then access the
disassembly via a menu: Debug menu -> Windows -> Disassembly.

<figure>
  <img src="/blog/20231105_why_is_c_faster_than_c/vs_disassembly.png"
  alt=""
  width="933"
  loading="lazy" />
  <figcaption>How to show native disassembly of your C# program</figcaption>
</figure>

This process makes sense, as .NET executables are distributed in .NET's
intermediate language format (IL), and IL is only compiled to native code by the
JIT as needed. [^1] [^2]

See the [appendix]({{< ref "#assembly" >}}) for the C# disassembly.

## What does it all mean?
Having the machine code generated from the C and C# code let me do a like for
like comparison of each program. I've put the assembly code of just the for
loops in an [appendix]({{< ref "#assembly" >}}) at the end of this post.

The first challenge was understanding what all the instructions meant! This
[quick introduction to x64 assembly](https://www.intel.com/content/dam/develop/external/us/en/documents/introduction-to-x64-assembly-181178.pdf)
(pdf) was a good primer. This [x86 reference](https://www.felixcloutier.com/x86/)
got me the rest of the way to a basic understanding of what was happening.
Rather than decode every instruction and figure out which variables were being
stored in which registers, I thought I'd just play around with the C compilation
options to get a feel for what changes.

Gcc has many options to control the generated machine code. I'll summarise the
relevant options here. For more details, see [gcc's optimize options](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html)
and [gcc options summary](https://gcc.gnu.org/onlinedocs/gcc/Option-Summary.html).

I found that the top contributors to program run time were
`-O3 -march=native -fassociative-math -fno-signed-zeros -fno-trapping-math`.

- `O1`, `O2`, `O3` are shorthand for a collection of optimisation settings, `O3`
  being the highest setting
- `-march=native`: compile for the host CPU, using any instructions it supports.
  This is generally only done for numerically intensive code, at the cost of
  portability. Most widely distributed C programs won't use this option, as it
  limits the number of CPUs the program can run on. For more details see this
  stack overflow question: [Why is -march=native used so rarely?](https://stackoverflow.com/questions/52653025/why-is-march-native-used-so-rarely)
- `-fassociative-math`: reorders floating point operations for efficiency,
  possibly causing under/overflow/NaNs
- `-fno-signed-zeros`: ignore the sign of zeros
- `-fno-trapping-math`: assume that there will be no "division by zero, overflow,
  underflow, inexact result and invalid operation"

The last three options may cause violations of IEEE or ANSI standards, and are
referred to as [unsafe math optimizations](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html#index-funsafe-math-optimizations).
I assume this is not necessarily a bad thing, if you know what you're doing.
Indeed, the value of pi calculated with these options varied slightly from the
value calculated without them (and by the C# code), but all calculated pi values
were still accurate to 7 decimal places.

Using just the `-O3` option, the C program took 120ms, which is the same as C#
program, ignoring start-up time. `-march=native` didn't make a big difference
unless the unsafe math options were enabled. If you compare the assembly of the
'unsafe' and the 'safe' options, you can see that the unsafe assembly uses `ymm`
registers (256 bit registers), allowing more calculations to be done per CPU
instruction. It also only loops 12.5 million times, versus the 100 million times
for the safe assembly. Intuitively, this explains the speedup to me: The unsafe
assembly runs 8x fewer loops, but runs about twice as many instructions per
loop, resulting in a 4x speedup. I don't know if that's the exact reason, but
I'm satisfied enough with that answer for now.

I don't understand why the C# program is as fast as the safe C. They both loop
100 million times, but the C# disassembly has more than twice as many instructions.
Maybe the C# disassembly viewed from the debugger isn't actually what gets run
when the debugger isn't attached. **todo** try

https://stackoverflow.com/a/38159398/2670469: can't if process exits quickly
    - good tip tho: menu route alerts JIT that you're trying to debug, output is different
https://stackoverflow.com/a/4042545/2670469: same result as vsjitdebugger X
run vs as admin, go to terminal, run vsjitdebugger bin/Release....
    - may be no good. no debugging info, just stepping through mountains of CLR
      code to try to find my code. can save breakpoints, but addresses aren't
      guaranteed to be the same between runs
    - change approach: attempt to load debug symbols from wherever u can find them
        - MS servers
        - debug again. seems to take multiple goes to load all symbols?
        - spent hours stepping through, still missed the call to my code.
          Found the assembly though! ARGGHHH it's almost identical!! :((

```asm
00007FFF89470715  vmovsd      xmm0,qword ptr [rbp-50h]
00007FFF8947071A  vmulsd      xmm0,xmm0,mmword ptr [7FFF894707C0h]
00007FFF89470722  vmovsd      qword ptr [rbp-50h],xmm0
00007FFF89470727  vmovsd      xmm0,qword ptr [rbp-50h]
00007FFF8947072C  mov         eax,dword ptr [rbp-54h]
00007FFF8947072F  lea         eax,[rax*2-1]
00007FFF89470736  vxorps      xmm1,xmm1,xmm1
00007FFF8947073A  vcvtsi2sd   xmm1,xmm1,eax
00007FFF8947073E  vdivsd      xmm0,xmm0,xmm1
00007FFF89470742  vaddsd      xmm0,xmm0,mmword ptr [rbp-48h]
00007FFF89470747  vmovsd      qword ptr [rbp-48h],xmm0
00007FFF8947074C  mov         eax,dword ptr [rbp-54h]
00007FFF8947074F  inc         eax
00007FFF89470751  mov         dword ptr [rbp-54h],eax
00007FFF89470754  mov         ecx,dword ptr [rbp-60h]
00007FFF89470757  dec         ecx
00007FFF89470759  mov         dword ptr [rbp-60h],ecx
00007FFF8947075C  cmp         dword ptr [rbp-60h],0
00007FFF89470760  jg          00007FFF89470770
00007FFF89470762  lea         rcx,[rbp-60h]
00007FFF89470766  mov         edx,49h
00007FFF8947076B  call        JIT_Patchpoint (07FFFE8EBC9B0h)
00007FFF89470770  mov         eax,dword ptr [rbp-3Ch]
00007FFF89470773  add         eax,2
00007FFF89470776  cmp         dword ptr [rbp-54h],eax
00007FFF89470779  jl          00007FFF89470715
```

    Next try: https://learn.microsoft.com/en-us/archive/blogs/vancem/how-to-use-visual-studio-to-investigate-code-generation-questions-in-managed-code
    - nup, assm still the same, const func doesn't get inlined
    - plus when stepping through the assembly, the instruction pointer jumps from
      00007FFF89470751 to 00007FFF89470776. Seems like the code between these
      points has been optimised away, but the disassembly view doesn't know about it???
    **todo**
        - do this: https://mijailovic.net/2018/07/05/generated-code/
        - try other tools here?: https://mijailovic.net/2018/07/05/generated-code/
        - also shows some vectorization

    turn on suppress jit optimisation:

```asm
00007FFF17B10FCD  vmovsd      xmm0,qword ptr [rbp-18h]
00007FFF17B10FD2  vmulsd      xmm0,xmm0,mmword ptr [Program.<Main>$(System.String[])+0E8h (07FFF17B11058h)]
00007FFF17B10FDA  vmovsd      qword ptr [rbp-18h],xmm0
00007FFF17B10FDF  vmovsd      xmm0,qword ptr [rbp-18h]
00007FFF17B10FE4  mov         eax,dword ptr [rbp-1Ch]
00007FFF17B10FE7  lea         eax,[rax*2-1]
00007FFF17B10FEE  vxorps      xmm1,xmm1,xmm1
00007FFF17B10FF2  vcvtsi2sd   xmm1,xmm1,eax
00007FFF17B10FF6  vdivsd      xmm0,xmm0,xmm1
00007FFF17B10FFA  vaddsd      xmm0,xmm0,mmword ptr [rbp-10h]
00007FFF17B10FFF  vmovsd      qword ptr [rbp-10h],xmm0
00007FFF17B11004  mov         eax,dword ptr [rbp-1Ch]
00007FFF17B11007  inc         eax
00007FFF17B11009  mov         dword ptr [rbp-1Ch],eax
00007FFF17B1100C  mov         eax,dword ptr [rbp-4]
00007FFF17B1100F  add         eax,2
00007FFF17B11012  cmp         dword ptr [rbp-1Ch],eax
00007FFF17B11015  jl          Program.<Main>$(System.String[])+05Dh (07FFF17B10FCDh)
```

    fewer lines!? is the setting backwards?
    also, the assembly adds 2 to rounds every loop, even though this value is
    a constant. I don't believe the optimised code would do this. Doing it manually
    in code made no difference to the run time. I'm pretty convinced that this
    functionality is broken in VS, and that the actual optimised assembly running
    is not what I was able to extract using VS.

    Try BenchmarkDotNet + DisassemblyDiagnoser as suggested here https://mijailovic.net/2018/07/05/generated-code/
    Yay! The output looks very similar to C, even 2 instructions shorter:

```asm
M01_L00:
  vmulsd    xmm0,xmm0,xmm2
  lea       edx,[rax*2-1]
  vxorps    xmm3,xmm3,xmm3
  vcvtsi2sd xmm3,xmm3,edx
  vdivsd    xmm3,xmm0,xmm3
  vaddsd    xmm1,xmm3,xmm1
  inc       eax
  cmp       eax,5F5E102
  jl        short M01_L00
```

    I dunno WTF is going on with VS, it's super frustrating that the docs are rather
    scattered and wrong (at least in this case. Following the steps here worked: https://mijailovic.net/2018/07/05/generated-code/,
    but not for the leibniz code). I'm glad I finally got assembly that matches my expectations.


## Vectorization
What gcc is doing with the unsafe compilation options above is vectorizing the
loop. There's a great explanation of vectorization here: [Stack Overflow: What is "vectorization"?](https://stackoverflow.com/questions/1422149/what-is-vectorization).
In a sentence, it's the compiler generating machine code that loops fewer times,
doing more per loop, and more per CPU instruction.

Gcc was able to automatically vectorize the C code, albeit with the unsafe math
options. The C programmer also needed to know that writing
`double x = -1.0 + 2.0 * (i & 0x1)` allows the compiler to vectorize, while `x *= -1`
doesn't. I didn't investigate why, but I assume it's due to the first code
determining the value of `x` using only the loop counter, while the second code
determines `x` from the value of `x` in the previous loop.

It's also possible to write vectorized code yourself, as demonstrated by the
[leibniz_avx2.cpp](https://github.com/niklas-heer/speed-comparison/blob/master/src/leibniz_avx2.cpp)
code in speed-comparison. On my machine, this beat the auto-vectorized C by a
couple of milliseconds, without needing the unsafe math options. Java and C# also
support manual vectorization, however the result in speed-comparison is underwhelming:
[this vectorized Java code](https://github.com/niklas-heer/speed-comparison/blob/master/src/leibnizVecOps.java)
performs 3 times worse than its [non-vectorized counterpart](https://github.com/niklas-heer/speed-comparison/blob/master/src/leibniz.java)!
It'd be interesting to see if C# fares any better. [Microsoft remarks](https://learn.microsoft.com/en-us/dotnet/standard/simd):

> SIMD [vectorization] is more likely to remove one bottleneck and expose the
> next, for example memory throughput. In general the performance benefit of
> using SIMD varies depending on the specific scenario, and in some cases it can
> even perform worse than simpler non-SIMD equivalent code.


# The end
So there we have it! For this particular code, C runs 5x faster than C# by
relaxing some strict IEEE calculation rules, auto-vectorizing the loop, and
having a very low start-up time.

Ignoring start-up time, C# was as fast as standards-compliant C, but vastly
outperformed by manually vectorized C++ code. It may be possible to manually
vectorize the C# code, but I'll leave that for a later post.

It's important to note that the code compared in this post is by no means a fair
comparison of the performance of C and C# in general, and there are many more
factors to consider when choosing a programming language. Have a look at the
links in [appendix B]({{< ref "#readings" >}}) for some more perspective.


# Appendix A: assembly {#assembly}
Assembly for C and C#. Only the pi calculation loop is shown.

C with unsafe math optimizations: (`-O3 -march=native -fassociative-math -fno-signed-zeros -fno-trapping-math`, 30ms):
```asm
;address:  instruction (bytes)   instruction (assembly)        # my understanding of what's happening
1130:      c5 fd 6f c2           vmovdqa ymm0,ymm2             # ymm0 = ymm2
1134:      ff c0                 inc    eax                    # eax += 1
1136:      c5 ed fe d7           vpaddd ymm2,ymm2,ymm7         # ymm2 += (4xi64)ymm7
113a:      c5 fd db ce           vpand  ymm1,ymm0,ymm6         # ymm1 = (4xi64)ymm0 & ymm6
113e:      c5 fd 72 f0 01        vpslld ymm0,ymm0,0x1          # ymm0 <<= 1, ie. ymm0 *= 2
1143:      c5 fd fe c5           vpaddd ymm0,ymm0,ymm5         # ymm0 += ymm5     (ymm5 = -1?, see 1117)
1147:      c5 7e e6 c9           vcvtdq2pd ymm9,xmm1           # (4xi64) ymm9 = (4x double?)xmm1 ... https://www.felixcloutier.com/x86/cvtdq2pd
114b:      c4 e3 7d 39 c9 01     vextracti128 xmm1,ymm1,0x1    # xmm1 = ymm1[255:128]
1151:      c5 fe e6 c9           vcvtdq2pd ymm1,xmm1           # (4xi64) ymm1 = (4x double?)xmm1
1155:      c5 7e e6 d0           vcvtdq2pd ymm10,xmm0          # (4xi64) ymm10 = (4x double?)xmm0
1159:      c4 e3 7d 39 c0 01     vextracti128 xmm0,ymm0,0x1    # xmm0 = ymm0[255:128]
115f:      c4 62 e5 98 cc        vfmadd132pd ymm9,ymm3,ymm4    # (4x double): ymm9 = ymm9 * ymm4 + ymm3
1164:      c5 fe e6 c0           vcvtdq2pd ymm0,xmm0           # (4xi64) ymm0 = (4x double?)xmm0
1168:      c4 e2 e5 98 cc        vfmadd132pd ymm1,ymm3,ymm4    # (4x double): ymm1 = ymm1 * ymm4 + ymm3
116d:      c4 41 35 5e ca        vdivpd ymm9,ymm9,ymm10        # ymm9 /= ymm10
1172:      c5 f5 5e c0           vdivpd ymm0,ymm1,ymm0         # ymm0 = ymm1/ymm0
1176:      c5 b5 58 c0           vaddpd ymm0,ymm9,ymm0         # ymm0 += ymm9
117a:      c5 3d 58 c0           vaddpd ymm8,ymm8,ymm0         # ymm8 += ymm0
117e:      3d 20 bc be 00        cmp    eax,0xbebc20           # if eax != 12500000 (=100M/8)
1183:      75 ab                 jne    1130 <main+0x90>       # goto 1130
```

Safe C (`-O3 -march=native`, 120ms):
```asm
;address:  instruction (bytes)   instruction (assembly)        # my understanding of what's happening
1120:      89 c1                 mov    ecx,eax                # ecx = eax
1122:      c5 e3 2a d2           vcvtsi2sd xmm2,xmm3,edx       # xmm2 = (double)edx?  https://www.felixcloutier.com/x86/cvtsi2sd
1126:      ff c0                 inc    eax                    # eax += 1
1128:      83 c2 02              add    edx,0x2                # edx += 2
112b:      83 e1 01              and    ecx,0x1                # ecx &= 1
112e:      c5 e3 2a c9           vcvtsi2sd xmm1,xmm3,ecx       # xmm1 = (double)ecx?
1132:      c4 e2 d9 99 cd        vfmadd132sd xmm1,xmm4,xmm5    # xmm1 = xmm1 * xmm5 + xmm4
1137:      c5 f3 5e ca           vdivsd xmm1,xmm1,xmm2         # xmm1 /= xmm2
113b:      c5 fb 58 c1           vaddsd xmm0,xmm0,xmm1         # xmm0 += xmm1
113f:      3d 02 e1 f5 05        cmp    eax,0x5f5e102          # if eax != 100M+2
1144:      75 da                 jne    1120 <main+0x80>       # goto 1120
```

C# (Visual Studio, Release, not optimised):
```asm
;address          instruction (assembly)                      # my understanding of what's happening
00007FFF1835417B  vmovsd      xmm0,qword ptr [rbp-48h]        # xmm0 = *(rbp-48h)
00007FFF18354180  vmulsd      xmm0,xmm0,                      # xmm0 = xmm0 * *(07FFF18354210)    mmword ptr [Program.<<Main>$>g__CalcPi|0_0()+0E0h (07FFF18354210h)]
00007FFF18354188  vmovsd      qword ptr [rbp-48h],xmm0        # *(rbp-48h) = xmm0
00007FFF1835418D  vmovsd      xmm0,qword ptr [rbp-48h]        # xmm0 = *(rbp-48h)
00007FFF18354192  mov         eax,dword ptr [rbp-4Ch]         # eax = *(rbp-4Ch)
00007FFF18354195  lea         eax,[rax*2-1]                   # eax = *(rax*2-1)
00007FFF1835419C  vxorps      xmm1,xmm1,xmm1                  # xmm1 = 0
00007FFF183541A0  vcvtsi2sd   xmm1,xmm1,eax                   # xmm1 = (double)eax?  https://www.felixcloutier.com/x86/cvtsi2sd
00007FFF183541A4  vdivsd      xmm0,xmm0,xmm1                  # xmm0 /= xmm1
00007FFF183541A8  vaddsd      xmm0,xmm0,mmword ptr [rbp-40h]  # xmm0 += *(rbp-40h)
00007FFF183541AD  vmovsd      qword ptr [rbp-40h],xmm0        # *(rbp-40h) = xmm0
00007FFF183541B2  mov         eax,dword ptr [rbp-4Ch]         # eax = *(rbp-4Ch)
00007FFF183541B5  inc         eax                             # eax += 1
00007FFF183541B7  mov         dword ptr [rbp-4Ch],eax         # *(rbp-4Ch) = eax
00007FFF183541BA  mov         ecx,dword ptr [rbp-58h]         # ecx = *(rbp-58h)
00007FFF183541BD  dec         ecx                             # ecx -= 1
00007FFF183541BF  mov         dword ptr [rbp-58h],ecx         # *(rbp-58h) = ecx
00007FFF183541C2  cmp         dword ptr [rbp-58h],0           # if *(rbp-58h) > 0
00007FFF183541C6  jg                                          # goto 07FFF183541D6   Program.<<Main>$>g__CalcPi|0_0()+0A6h (07FFF183541D6h)
00007FFF183541C8  lea         rcx,[rbp-58h]                   # rcx = *(rbp-58h)
00007FFF183541CC  mov         edx,33h                         # edx = 51
00007FFF183541D1  call        00007FFF77D8C9B0                # call mystery function. appears to be JIT related
00007FFF183541D6  cmp         dword ptr [rbp-4Ch],5F5E102h    # if *(rbp-4Ch) < 100M +2
00007FFF183541DD  jl                                          # goto 07FFF1835417B
```

# Appendix B: Interesting reading {#readings}
- [Is C# slower than say C++?](https://stackoverflow.com/questions/5326269/is-c-sharp-really-slower-than-say-c)
    - [detailed generic answer](https://stackoverflow.com/a/5331574/2670469)
        - covers language features, VM, GC, benchmarks
        - conclusion: you can almost always write C/C++ that's faster than C#,
          but not the other way around
    - [specific case answer](https://stackoverflow.com/a/37103437/2670469)
        - yes, but it may take a C++ expert significant time to make it run
          faster than C#
- [Jeff Atwood: The bloated world of Managed Code](https://blog.codinghorror.com/the-bloated-world-of-managed-code/)
    - C# cons: slower, uses more memory
    - C# pros: faster development
- [Jeff Atwood: On Managed Code Performance](https://blog.codinghorror.com/on-managed-code-performance/)
    - C# pro: security: buffer overruns possible in C/C++ can't happen in C#
    - quake 2 .NET port was initially faster than the C version, but 15% slower
      after C targeted the host CPU, and 30% slower than the hand-optimised
      assembly version


# References
[^1]: [.NET assembly file format](https://learn.microsoft.com/en-us/dotnet/standard/assembly/file-format)
[^2]: [Compiling MSIL to Native Code](https://learn.microsoft.com/en-us/dotnet/standard/managed-execution-process#compiling-msil-to-native-code)
